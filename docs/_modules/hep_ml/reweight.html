

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>hep_ml.reweight &mdash; hep_ml 0.7.4.dev5+gba709f3.d20250617 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />

  
      <script src="../../_static/documentation_options.js?v=a931b840"></script>
      <script src="../../_static/doctools.js?v=9a2dae69"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            hep_ml
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../index.html">hep_ml documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../gb.html">Gradient boosting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../losses.html">Losses for Gradient Boosting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../uboost.html">uBoost</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../metrics.html">Metric functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../preprocessing.html">Preprocessing data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reweight.html">Reweighting algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../speedup.html">Fast predictions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../splot.html">sPlot</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks.html">Code Examples</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">hep_ml</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">hep_ml.reweight</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for hep_ml.reweight</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">**hep_ml.reweight** contains reweighting algorithms.</span>

<span class="sd">Reweighting is procedure of finding such weights for original distribution,</span>
<span class="sd">that make distribution of one or several variables identical in original distribution and target distribution.</span>

<span class="sd">Typical application of this technique in HEP is reweighting of Monte-Carlo simulation results to minimize</span>
<span class="sd">disagreement between simulated data and real data.</span>
<span class="sd">Frequently the reweighting rule is trained on one part of data (normalization channel)</span>
<span class="sd">and applied to different (signal channel).</span>

<span class="sd">Remark: if each variable has identical distribution in two samples,</span>
<span class="sd">this doesn&#39;t imply that multidimensional distributions are equal (almost surely they aren&#39;t).</span>
<span class="sd">Aim of reweighters is to get identical multidimensional distributions.</span>

<span class="sd">Algorithms are implemented as estimators, fitting and reweighting stages are split.</span>
<span class="sd">Fitted reweighter can be applied many times to different data, pickled and so on.</span>

<span class="sd">Remark: The normalization constant in the reweighters is not fixed. This is to ensure that the</span>
<span class="sd">output of `reweighter.predict_weights` is deterministic; for example, if you predict weights for</span>
<span class="sd">a large sample all at once or predict weights separately for each event and then concantenate the</span>
<span class="sd">predictions, the result will be the same---the results would be different were the weights automatically</span>
<span class="sd">normalized to the number of events. If normalization plays a significant role in your application,</span>
<span class="sd">you should normalize the weights yourself.</span>

<span class="sd">Folding over reweighter is also availabel. This provides an easy way to run k-Folding cross-validation.</span>
<span class="sd">Also it is a nice way to combine weights predictions of trained reweighters.</span>

<span class="sd">Examples</span>
<span class="sd">________</span>

<span class="sd">The most common use case is reweighting of Monte-Carlo simulations results to sPlotted real data.</span>
<span class="sd">(original weights are all equal to 1 and could be skipped, but left here for example)</span>

<span class="sd">&gt;&gt;&gt; from hep_ml.reweight import BinsReweighter, GBReweighter</span>
<span class="sd">&gt;&gt;&gt; original_weights = numpy.ones(len(MC_data))</span>
<span class="sd">&gt;&gt;&gt; reweighter = BinsReweighter(n_bins=100, n_neighs=3)</span>
<span class="sd">&gt;&gt;&gt; reweighter.fit(original=MC_data, target=RealData,</span>
<span class="sd">&gt;&gt;&gt;                original_weight=original_weights, target_weight=sWeights)</span>
<span class="sd">&gt;&gt;&gt; MC_weights = reweighter.predict_weights(MC_data, original_weight=original_weights)</span>

<span class="sd">The same example for `GBReweighter`:</span>

<span class="sd">&gt;&gt;&gt; reweighter = GBReweighter(max_depth=2, gb_args={&#39;subsample&#39;: 0.5})</span>
<span class="sd">&gt;&gt;&gt; reweighter.fit(original=MC_data, target=RealData, target_weight=sWeights)</span>
<span class="sd">&gt;&gt;&gt; MC_weights = reweighter.predict_weights(MC_data)</span>

<span class="sd">Folding over reweighter:</span>

<span class="sd">&gt;&gt;&gt; reweighter_base = GBReweighter(max_depth=2, gb_args={&#39;subsample&#39;: 0.5})</span>
<span class="sd">&gt;&gt;&gt; reweighter = FoldingReweighter(reweighter_base, n_folds=3)</span>
<span class="sd">&gt;&gt;&gt; reweighter.fit(original=MC_data, target=RealData, target_weight=sWeights)</span>

<span class="sd">If the same data used in the training process are predicted by folding reweighter</span>
<span class="sd">weights predictions will be unbiased: each reweighter predicts only those part of data which is not used during its training</span>

<span class="sd">&gt;&gt;&gt; MC_weights = reweighter.predict_weights(MC_data)</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.ndimage</span><span class="w"> </span><span class="kn">import</span> <span class="n">gaussian_filter</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn</span><span class="w"> </span><span class="kn">import</span> <span class="n">clone</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.base</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseEstimator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">check_random_state</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">.</span><span class="w"> </span><span class="kn">import</span> <span class="n">gradientboosting</span> <span class="k">as</span> <span class="n">gb</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.</span><span class="w"> </span><span class="kn">import</span> <span class="n">losses</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.commonutils</span><span class="w"> </span><span class="kn">import</span> <span class="n">check_sample_weight</span><span class="p">,</span> <span class="n">weighted_quantile</span>

<span class="n">__author__</span> <span class="o">=</span> <span class="s2">&quot;Alex Rogozhnikov, Tatiana Likhomanenko&quot;</span>
<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;BinsReweighter&quot;</span><span class="p">,</span> <span class="s2">&quot;FoldingReweighter&quot;</span><span class="p">,</span> <span class="s2">&quot;GBReweighter&quot;</span><span class="p">]</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_bincount_nd</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">shape</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Does the same thing as numpy.bincount, but allows binning in several integer variables.</span>
<span class="sd">    :param x: numpy.array of shape [n_samples, n_features] with non-negative integers</span>
<span class="sd">    :param weights: weights of samples, array of shape [n_samples]</span>
<span class="sd">    :param shape: shape of result, should be greater, then maximal value</span>
<span class="sd">    :return: weighted number of event in each bin, of shape=shape</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;length of weight is different: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;wrong length of shape: </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="n">maximals</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">numpy</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">maximals</span> <span class="o">&lt;</span> <span class="n">shape</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;small shape passed: </span><span class="si">{</span><span class="n">maximals</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span>

    <span class="n">result</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">numpy</span><span class="o">.</span><span class="n">add</span><span class="o">.</span><span class="n">at</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">T</span><span class="p">),</span> <span class="n">weights</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>


<span class="k">class</span><span class="w"> </span><span class="nc">ReweighterMixin</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Supplementary class which shows the interface of reweighter.</span>
<span class="sd">    Reweighters should be derived from this class.&quot;&quot;&quot;</span>

    <span class="n">n_features_</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_normalize_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Normalize input of reweighter</span>
<span class="sd">        :param data: array like of shape [n_samples] or [n_samples, n_features]</span>
<span class="sd">        :param weights: array-like of shape [n_samples] or None</span>
<span class="sd">        :return: tuple with</span>
<span class="sd">            data - numpy.array of shape [n_samples, n_features]</span>
<span class="sd">            weights - numpy.array of shape [n_samples] with mean = 1.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">check_sample_weight</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_features_</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_features_</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_features_</span> <span class="o">==</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="sa">f</span><span class="s2">&quot;number of features is wrong: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_features_</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">return</span> <span class="n">data</span><span class="p">,</span> <span class="n">weights</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">original</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">original_weight</span><span class="p">,</span> <span class="n">target_weight</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;To be overriden in descendants&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">predict_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">original</span><span class="p">,</span> <span class="n">original_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;To be overriden in descendants&quot;</span><span class="p">)</span>


<div class="viewcode-block" id="BinsReweighter">
<a class="viewcode-back" href="../../reweight.html#hep_ml.reweight.BinsReweighter">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">BinsReweighter</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">ReweighterMixin</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_bins</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">n_neighs</span><span class="o">=</span><span class="mf">3.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Use bins for reweighting. Bins&#39; edges are computed using quantiles along each axis</span>
<span class="sd">        (which is better than bins of even size).</span>

<span class="sd">        This method works fine for 1d/2d histograms,</span>
<span class="sd">        while being unstable or inaccurate for higher dimensions.</span>

<span class="sd">        To make computed rule more smooth and stable, after computing weights in bins,</span>
<span class="sd">        gaussian filter is applied (so reweighting coefficient also includes information from neighbouring bins).</span>

<span class="sd">        :param int n_bins: how many bins to use for each input variable.</span>
<span class="sd">        :param float n_neighs: size of gaussian filter (in bins).</span>
<span class="sd">            This parameter is responsible for tradeoff between stability of rule and accuracy of predictions.</span>
<span class="sd">            With increase of n_neighs the reweighting rule becomes more stable.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_bins</span> <span class="o">=</span> <span class="n">n_bins</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_neighs</span> <span class="o">=</span> <span class="n">n_neighs</span>
        <span class="c1"># if number of events in bins is less than this value, number of events is clipped.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_in_the_bin</span> <span class="o">=</span> <span class="mf">1.0</span>

<div class="viewcode-block" id="BinsReweighter.compute_bin_indices">
<a class="viewcode-back" href="../../reweight.html#hep_ml.reweight.BinsReweighter.compute_bin_indices">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">compute_bin_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute id of bin along each axis.</span>

<span class="sd">        :param data: data, array-like of shape [n_samples, n_features]</span>
<span class="sd">            with the same order of features as in training</span>
<span class="sd">        :return: numpy.array of shape [n_samples, n_features] with integers, each from [0, n_bins - 1]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">bin_indices</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">axis</span><span class="p">,</span> <span class="n">axis_edges</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">edges</span><span class="p">):</span>
            <span class="n">bin_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">(</span><span class="n">axis_edges</span><span class="p">,</span> <span class="n">data</span><span class="p">[:,</span> <span class="n">axis</span><span class="p">]))</span>
        <span class="k">return</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">bin_indices</span><span class="p">)</span><span class="o">.</span><span class="n">T</span></div>


<div class="viewcode-block" id="BinsReweighter.fit">
<a class="viewcode-back" href="../../reweight.html#hep_ml.reweight.BinsReweighter.fit">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">original</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">original_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">target_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Prepare reweighting formula by computing histograms.</span>

<span class="sd">        :param original: values from original distribution, array-like of shape [n_samples, n_features]</span>
<span class="sd">        :param target: values from target distribution, array-like of shape [n_samples, n_features]</span>
<span class="sd">        :param original_weight: weights for samples of original distributions</span>
<span class="sd">        :param target_weight: weights for samples of original distributions</span>
<span class="sd">        :return: self</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_features_</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">original</span><span class="p">,</span> <span class="n">original_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_normalize_input</span><span class="p">(</span><span class="n">original</span><span class="p">,</span> <span class="n">original_weight</span><span class="p">)</span>
        <span class="n">target</span><span class="p">,</span> <span class="n">target_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_normalize_input</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">target_weight</span><span class="p">)</span>
        <span class="n">target_perc</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_bins</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">edges</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_features_</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">edges</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">weighted_quantile</span><span class="p">(</span><span class="n">target</span><span class="p">[:,</span> <span class="n">axis</span><span class="p">],</span> <span class="n">quantiles</span><span class="o">=</span><span class="n">target_perc</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">target_weight</span><span class="p">))</span>

        <span class="n">bins_weights</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">weights</span> <span class="ow">in</span> <span class="p">[(</span><span class="n">original</span><span class="p">,</span> <span class="n">original_weight</span><span class="p">),</span> <span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">target_weight</span><span class="p">)]:</span>
            <span class="n">bin_indices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_bin_indices</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">bin_w</span> <span class="o">=</span> <span class="n">_bincount_nd</span><span class="p">(</span><span class="n">bin_indices</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_bins</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_features_</span><span class="p">)</span>
            <span class="n">smeared_weights</span> <span class="o">=</span> <span class="n">gaussian_filter</span><span class="p">(</span><span class="n">bin_w</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_neighs</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="mf">2.5</span><span class="p">)</span>
            <span class="n">bins_weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">smeared_weights</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">min_in_the_bin</span><span class="p">))</span>
        <span class="n">bin_orig_weights</span><span class="p">,</span> <span class="n">bin_targ_weights</span> <span class="o">=</span> <span class="n">bins_weights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transition</span> <span class="o">=</span> <span class="n">bin_targ_weights</span> <span class="o">/</span> <span class="n">bin_orig_weights</span>
        <span class="k">return</span> <span class="bp">self</span></div>


<div class="viewcode-block" id="BinsReweighter.predict_weights">
<a class="viewcode-back" href="../../reweight.html#hep_ml.reweight.BinsReweighter.predict_weights">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">predict_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">original</span><span class="p">,</span> <span class="n">original_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns corrected weights. Result is computed as original_weight * reweighter_multipliers.</span>

<span class="sd">        :param original: values from original distribution of shape [n_samples, n_features]</span>
<span class="sd">        :param original_weight: weights of samples before reweighting.</span>
<span class="sd">        :return: numpy.array of shape [n_samples] with new weights.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">original</span><span class="p">,</span> <span class="n">original_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_normalize_input</span><span class="p">(</span><span class="n">original</span><span class="p">,</span> <span class="n">original_weight</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">bin_indices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_bin_indices</span><span class="p">(</span><span class="n">original</span><span class="p">)</span>
        <span class="n">results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transition</span><span class="p">[</span><span class="nb">tuple</span><span class="p">(</span><span class="n">bin_indices</span><span class="o">.</span><span class="n">T</span><span class="p">)]</span> <span class="o">*</span> <span class="n">original_weight</span>
        <span class="k">return</span> <span class="n">results</span></div>
</div>



<div class="viewcode-block" id="GBReweighter">
<a class="viewcode-back" href="../../reweight.html#hep_ml.reweight.GBReweighter">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">GBReweighter</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">ReweighterMixin</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">n_estimators</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
        <span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
        <span class="n">loss_regularization</span><span class="o">=</span><span class="mf">5.0</span><span class="p">,</span>
        <span class="n">gb_args</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gradient Boosted Reweighter - a reweighter algorithm based on ensemble of regression trees.</span>
<span class="sd">        Parameters have the same role, as in gradient boosting.</span>
<span class="sd">        Special loss function is used, trees are trained to maximize symmetrized binned chi-squared statistics.</span>

<span class="sd">        Training takes much more time than for bin-based versions, but `GBReweighter` is capable</span>
<span class="sd">        to work in high dimensions while keeping reweighting rule reliable and precise</span>
<span class="sd">        (and even smooth if many trees are used).</span>

<span class="sd">        :param n_estimators: number of trees</span>
<span class="sd">        :param learning_rate: float from [0, 1]. Lesser learning rate requires more trees,</span>
<span class="sd">            but makes reweighting rule more stable.</span>
<span class="sd">        :param max_depth: maximal depth of trees</span>
<span class="sd">        :param min_samples_leaf: minimal number of events in the leaf.</span>
<span class="sd">        :param loss_regularization: float, approximately equal to number of events</span>
<span class="sd">         that algorithm &#39;puts&#39; in each leaf to prevent exploding.</span>
<span class="sd">        :param gb_args: other parameters passed to gradient boosting.</span>
<span class="sd">            Those are: subsample, min_samples_split, max_features, max_leaf_nodes</span>
<span class="sd">            For example: gb_args = {&#39;subsample&#39;: 0.8, &#39;max_features&#39;: 0.75}</span>
<span class="sd">            See :class:`hep_ml.gradientboosting.UGradientBoostingClassifier`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="n">n_estimators</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_depth</span> <span class="o">=</span> <span class="n">max_depth</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="n">min_samples_leaf</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gb_args</span> <span class="o">=</span> <span class="n">gb_args</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_regularization</span> <span class="o">=</span> <span class="n">loss_regularization</span>

<div class="viewcode-block" id="GBReweighter.fit">
<a class="viewcode-back" href="../../reweight.html#hep_ml.reweight.GBReweighter.fit">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">original</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">original_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">target_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Prepare reweighting formula by training sequence of trees.</span>

<span class="sd">        :param original: values from original distribution, array-like of shape [n_samples, n_features]</span>
<span class="sd">        :param target: values from target distribution, array-like of shape [n_samples, n_features]</span>
<span class="sd">        :param original_weight: weights for samples of original distributions</span>
<span class="sd">        :param target_weight: weights for samples of original distributions</span>
<span class="sd">        :return: self</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_features_</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">gb_args</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">gb_args</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">original</span><span class="p">,</span> <span class="n">original_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_normalize_input</span><span class="p">(</span><span class="n">original</span><span class="p">,</span> <span class="n">original_weight</span><span class="p">)</span>
        <span class="n">target</span><span class="p">,</span> <span class="n">target_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_normalize_input</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">target_weight</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">losses</span><span class="o">.</span><span class="n">ReweightLossFunction</span><span class="p">(</span><span class="n">regularization</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_regularization</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gb</span> <span class="o">=</span> <span class="n">gb</span><span class="o">.</span><span class="n">UGradientBoostingClassifier</span><span class="p">(</span>
            <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
            <span class="n">n_estimators</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span>
            <span class="n">max_depth</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_depth</span><span class="p">,</span>
            <span class="n">min_samples_leaf</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">min_samples_leaf</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
            <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">gb_args</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">original</span><span class="p">,</span> <span class="n">target</span><span class="p">])</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">original</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">target</span><span class="p">))</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">original_weight</span><span class="p">,</span> <span class="n">target_weight</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>


<div class="viewcode-block" id="GBReweighter.predict_weights">
<a class="viewcode-back" href="../../reweight.html#hep_ml.reweight.GBReweighter.predict_weights">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">predict_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">original</span><span class="p">,</span> <span class="n">original_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns corrected weights. Result is computed as original_weight * reweighter_multipliers.</span>

<span class="sd">        :param original: values from original distribution of shape [n_samples, n_features]</span>
<span class="sd">        :param original_weight: weights of samples before reweighting.</span>
<span class="sd">        :return: numpy.array of shape [n_samples] with new weights.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">original</span><span class="p">,</span> <span class="n">original_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_normalize_input</span><span class="p">(</span><span class="n">original</span><span class="p">,</span> <span class="n">original_weight</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">multipliers</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gb</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">original</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">multipliers</span> <span class="o">*</span> <span class="n">original_weight</span></div>
</div>



<div class="viewcode-block" id="FoldingReweighter">
<a class="viewcode-back" href="../../reweight.html#hep_ml.reweight.FoldingReweighter">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">FoldingReweighter</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">ReweighterMixin</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">base_reweighter</span><span class="p">,</span> <span class="n">n_folds</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This meta-regressor implements folding algorithm over reweighter:</span>

<span class="sd">        * training data is splitted into n equal parts;</span>

<span class="sd">        * we train n reweighters, each one is trained using n-1 folds</span>

<span class="sd">        To build unbiased predictions for data, pass the **same** dataset (with same order of events)</span>
<span class="sd">        as in training to `predict_weights`, in which case</span>
<span class="sd">        a reweighter will be used to predict each event that the reweighter didn&#39;t use it during training.</span>
<span class="sd">        To use information from not one, but several reweighters during predictions,</span>
<span class="sd">        provide appropriate voting function. Examples of voting function:</span>
<span class="sd">        &gt;&gt;&gt; voting = lambda x: numpy.mean(x, axis=0)</span>
<span class="sd">        &gt;&gt;&gt; voting = lambda x: numpy.median(x, axis=0)</span>

<span class="sd">        :param base_reweighter: base reweighter object</span>
<span class="sd">        :type base_reweighter: ReweighterMixin</span>
<span class="sd">        :param n_folds: number of folds</span>
<span class="sd">        :param random_state: random state for reproducibility</span>
<span class="sd">        :type random_state: None or int or RandomState</span>
<span class="sd">        :param bool verbose:</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_folds</span> <span class="o">=</span> <span class="n">n_folds</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_reweighter</span> <span class="o">=</span> <span class="n">base_reweighter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reweighters</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_random_number</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_length</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_folds_column</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">length</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return special column with indices of folds for all events.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_random_number</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_random_number</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100000</span><span class="p">)</span>
        <span class="n">folds_column</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">length</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_folds</span>
        <span class="n">folds_column</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_random_number</span><span class="p">)</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">folds_column</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">folds_column</span>

<div class="viewcode-block" id="FoldingReweighter.fit">
<a class="viewcode-back" href="../../reweight.html#hep_ml.reweight.FoldingReweighter.fit">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">original</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">original_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">target_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Prepare reweighting formula by training a sequence of trees.</span>

<span class="sd">        :param original: values from original distribution, array-like of shape [n_samples, n_features]</span>
<span class="sd">        :param target: values from target distribution, array-like of shape [n_samples, n_features]</span>
<span class="sd">        :param original_weight: weights for samples of original distributions</span>
<span class="sd">        :param target_weight: weights for samples of original distributions</span>
<span class="sd">        :return: self</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">original</span><span class="p">,</span> <span class="n">original_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_normalize_input</span><span class="p">(</span><span class="n">original</span><span class="p">,</span> <span class="n">original_weight</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">target</span><span class="p">,</span> <span class="n">target_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_normalize_input</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">target_weight</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="n">folds_original</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_folds_column</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">original</span><span class="p">))</span>
        <span class="n">folds_target</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_folds_column</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">target</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_folds</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reweighters</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">clone</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_reweighter</span><span class="p">))</span>

        <span class="n">original</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">original</span><span class="p">)</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_folds</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reweighters</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
                <span class="n">original</span><span class="p">[</span><span class="n">folds_original</span> <span class="o">!=</span> <span class="n">i</span><span class="p">,</span> <span class="p">:],</span>
                <span class="n">target</span><span class="p">[</span><span class="n">folds_target</span> <span class="o">!=</span> <span class="n">i</span><span class="p">,</span> <span class="p">:],</span>
                <span class="n">original_weight</span><span class="o">=</span><span class="n">original_weight</span><span class="p">[</span><span class="n">folds_original</span> <span class="o">!=</span> <span class="n">i</span><span class="p">],</span>
                <span class="n">target_weight</span><span class="o">=</span><span class="n">target_weight</span><span class="p">[</span><span class="n">folds_target</span> <span class="o">!=</span> <span class="n">i</span><span class="p">],</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">original</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>


<div class="viewcode-block" id="FoldingReweighter.predict_weights">
<a class="viewcode-back" href="../../reweight.html#hep_ml.reweight.FoldingReweighter.predict_weights">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">predict_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">original</span><span class="p">,</span> <span class="n">original_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vote_function</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns corrected weights. Result is computed as original_weight * reweighter_multipliers.</span>

<span class="sd">        :param original: values from original distribution of shape [n_samples, n_features]</span>
<span class="sd">        :param original_weight: weights of samples before reweighting.</span>
<span class="sd">        :return: numpy.array of shape [n_samples] with new weights.</span>
<span class="sd">        :param vote_function: if using averaging over predictions of folds, this function shall be passed.</span>
<span class="sd">            For instance: lambda x: numpy.mean(x, axis=0), which means averaging result over all folds.</span>
<span class="sd">            Another useful option is lambda x: numpy.median(x, axis=0)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">original</span><span class="p">,</span> <span class="n">original_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_normalize_input</span><span class="p">(</span><span class="n">original</span><span class="p">,</span> <span class="n">original_weight</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">vote_function</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;KFold prediction with voting function&quot;</span><span class="p">)</span>
            <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">reweighter</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">reweighters</span><span class="p">:</span>
                <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reweighter</span><span class="o">.</span><span class="n">predict_weights</span><span class="p">(</span><span class="n">original</span><span class="p">,</span> <span class="n">original_weight</span><span class="o">=</span><span class="n">original_weight</span><span class="p">))</span>
            <span class="c1"># results: [n_classifiers, n_samples], reduction is expected over 0th axis</span>
            <span class="n">results</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">vote_function</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">original</span><span class="p">)</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_length</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span>
                        <span class="s2">&quot;KFold prediction using random reweighter (length of data passed not equal to length of train)&quot;</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;KFold prediction using folds column&quot;</span><span class="p">)</span>
            <span class="n">folds_original</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_folds_column</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">original</span><span class="p">))</span>
            <span class="n">new_original_weight</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">original</span><span class="p">))</span>
            <span class="n">original</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">original</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_folds</span><span class="p">):</span>
                <span class="n">new_original_weight</span><span class="p">[</span><span class="n">folds_original</span> <span class="o">==</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reweighters</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">predict_weights</span><span class="p">(</span>
                    <span class="n">original</span><span class="p">[</span><span class="n">folds_original</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="p">:],</span> <span class="n">original_weight</span><span class="o">=</span><span class="n">original_weight</span><span class="p">[</span><span class="n">folds_original</span> <span class="o">==</span> <span class="n">i</span><span class="p">]</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="n">new_original_weight</span></div>
</div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2015-2017, Yandex; Alex Rogozhnikov and contributors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>
